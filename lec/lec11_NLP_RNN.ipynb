{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d557b4b-18f3-4965-b960-f07644259dc1",
   "metadata": {
    "tags": []
   },
   "source": [
    "<font size=6><b>Lec08.NLP RNN\n",
    "* <b>RNN(Recurrent Neural Network) : 순환 신경망\n",
    "* <b>LSTM(Long Short-Term Memory) : 장단기 기억 신경망\n",
    "* <b>BiLSTM(Bidirectional LSTM) : 양방향 LSTM 신경망\n",
    "* <b>GRU(Gated Recurrent Unit) : 게이트 순환 유닛 신경망"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57f0f12b-0360-4e33-b2cd-2b37289a499f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container{width:100% !important;}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "sns.set()\n",
    "\n",
    "#-------------------- 차트 관련 속성 (한글처리, 그리드) ---------ㅊ--\n",
    "plt.rcParams['font.family']= 'Malgun Gothic'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "#-------------------- 주피터 , 출력결과 넓이 늘리기 ---------------\n",
    "# from IPython.core.display import display, HTML\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "display(HTML(\"<style>.container{width:100% !important;}</style>\"))\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('max_colwidth', None)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6efd51-d1fe-4095-87ad-00c856073d92",
   "metadata": {},
   "source": [
    "# RNN\n",
    "* RNN(Recurrent Neural Network) : 순환 신경망\n",
    "* 입력과 출력을 시퀀스 단위로 처리하는 시퀀스(Sequence) 모델\n",
    "* 가장 기본적인 인공 신경망 시퀀스 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a98656-8d4a-4776-9431-9e0c339aa527",
   "metadata": {},
   "source": [
    "<table>\n",
    "    <tr><td><img src=\"https://wikidocs.net/images/page/22886/rnn_image4_ver2.PNG\"></td>\n",
    "        <td><img width=200 src=\"https://wikidocs.net/images/page/22888/vanilla_rnn_ver2.PNG\"></td></tr></table><br>\n",
    "입력층 : $h_{t} = tanh(W_{x} x_{t} + W_{h}h_{t−1} + b)$        <br>\n",
    "출력층 : $y_{t} = f(W_{y}h_{t} + b)$ <br><br>\n",
    "<img src=\"https://wikidocs.net/images/page/22886/rnn_images4-5.PNG\">\n",
    "<img src=\"https://wikidocs.net/images/page/22886/rnn_image6between7.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554d69a3-b838-44f7-a92e-31edf3bc3e40",
   "metadata": {},
   "source": [
    "* 3D : (batch_size, timesteps, input_dim) 덩어리,행,렬\n",
    "* model.add(SimpleRNN(hidden_units, input_shape=(timesteps=행수, input_dim=열수)))\n",
    "* model.add(SimpleRNN(hidden_units, input_length=행수, input_dim=열수))\n",
    "* return_sequences = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85094920-1e82-463d-a71a-7be9355903f3",
   "metadata": {},
   "source": [
    "# LSTM\n",
    "* LSTM(Long Short-Term Memory) : 장단기 기억 신경망\n",
    "* 입력 게이트,  삭제 게이트,  셀 상태,  출력 게이트\n",
    "* ref : https://wikidocs.net/22888"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118f6aa9-516c-40d4-b871-ac9a81f90c3a",
   "metadata": {},
   "source": [
    "<img width=300 src=\"https://wikidocs.net/images/page/22888/vaniila_rnn_and_different_lstm_ver2.PNG\">\n",
    "<table>\n",
    "<tr>\n",
    "<td>입력 게이트</td>    \n",
    "<td><img width=200 src=\"https://wikidocs.net/images/page/22888/inputgate.PNG\"></td>\n",
    "<td>$i_{t}=σ(W_{xi}x_{t}+W_{hi}h_{t-1}+b_{i})$<br>\n",
    "    $g_{t}=tanh(W_{xg}x_{t}+W_{hg}h_{t-1}+b_{g})$</td>    \n",
    "</tr>\n",
    "<tr>\n",
    "<td>삭제 게이트</td>        \n",
    "<td><img width=200 src=\"https://wikidocs.net/images/page/22888/forgetgate.PNG\"></td>\n",
    "<td>$f_{t}=σ(W_{xf}x_{t}+W_{hf}h_{t-1}+b_{f})$</td>\n",
    "</tr>\n",
    "<tr> \n",
    "<td>셀 상태</td>        \n",
    "<td><img width=200 src=\"https://wikidocs.net/images/page/22888/cellstate2.PNG\"></td>\n",
    "<td>$C_{t}=f_{t}∘C_{t-1}+i_{t}∘g_{t}$</td>\n",
    "</tr>    \n",
    "<tr>\n",
    "<td>출력 게이트와 은닉 상태</td>        \n",
    "<td><img width=200 src=\"https://wikidocs.net/images/page/22888/outputgateandhiddenstate.PNG\"></td>\n",
    "<td>$o_{t}=σ(W_{xo}x_{t}+W_{ho}h_{t-1}+b_{o})$<br>\n",
    "    $h_{t}=o_{t}∘tanh(c_{t})$</td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9717d45d-19e9-4453-bf02-3e95d653fbca",
   "metadata": {
    "tags": []
   },
   "source": [
    "# BiLSTM\n",
    "* BiLSTM(Bidirectional LSTM) : 양방향 LSTM 신경망\n",
    "*  앞 시점의 은닉 상태(Forward States) 를 전달받아 현재의 은닉 상태를 계산\n",
    "* 뒤 시점의 은닉 상태(Backward States) 를 전달 받아 현재의 은닉 상태를 계산\n",
    "* 이 두 개의 값을 이용해 출력값 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f7abe0-bcd1-45e7-80ff-f30d090e9d23",
   "metadata": {},
   "source": [
    "<img src=\"https://wikidocs.net/images/page/22886/rnn_image5_ver2.PNG\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be59d2f3-a44d-47b1-855e-e6ae0afff786",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Bidirectional, SimpleRNN\n",
    "from keras.models import Sequential\n",
    "# timesteps = 10\n",
    "# input_dim = 5\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(Bidirectional(SimpleRNN(hidden_units, return_sequences=True), input_shape=(timesteps, input_dim)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1487494-48e4-4023-834f-fcd669eb14cb",
   "metadata": {},
   "source": [
    "# GRU\n",
    "* GRU(Gated Recurrent Unit) : 게이트 순환 유닛 신경망\n",
    "* LSTM의 간소화\n",
    "* ref : https://wikidocs.net/22889"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46444258-9e31-44b1-af61-d36b7ef4f187",
   "metadata": {},
   "source": [
    "<table><tr><td>\n",
    "<img width=200 src=\"https://wikidocs.net/images/page/22889/gru.PNG\">\n",
    "</td><td>\n",
    "$r_{t}=σ(W_{xr}x_{t}+W_{hr}h_{t-1}+b_{r})$ <br>\n",
    "$z_{t}=σ(W_{xz}x_{t}+W_{hz}h_{t-1}+b_{z}) $  <br>\n",
    "$g_{t}=tanh(W_{hg}(r_{t}∘h_{t-1})+W_{xg}x_{t}+b_{g})$  <br>\n",
    "    $h_{t}=(1-z_{t})∘g_{t}+z_{t}∘h_{t-1}$</td></tr></table><br>\n",
    "model.add(GRU(hidden_size, input_shape=(timesteps, input_dim)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f589b5-0f0d-42ca-9511-b40320ff9a10",
   "metadata": {},
   "source": [
    "# [실습]\n",
    "* RNN 이용 자연어처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357a006c-266d-474e-897b-1a0c96ae7772",
   "metadata": {},
   "source": [
    "## Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "433cb975-f5ce-4723-bba6-468643edeb10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2fb5b4d-719c-4f01-8ac7-fb1b19f2e8ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = fetch_20newsgroups(subset='train'\n",
    "                              , remove=('headers', 'footers', 'quotes')\n",
    "                              , categories=['alt.atheism','comp.sys.mac.hardware','sci.electronics','talk.politics.guns','comp.windows.x']\n",
    "                              , random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f544c212-4ce5-4d34-8258-f88421673b4f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'filenames', 'target_names', 'target', 'DESCR'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0eac16b3-63fd-49e5-b51b-3ee0ed38c2a4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'alt.atheism'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"target_names\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5496c16-ff16-413e-83c4-7c076f260682",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2783</th>\n",
       "      <td>\\nI used a bunch as weights, when building a model airplane.  Hung them\\non the stringers, across the stringer, or whatever.  Worked pretty well.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2784</th>\n",
       "      <td>I repair a lot of monitors here, and I'd like to know where I can get a\\npattern generator (or a circuit for one) that will provide MDA, EGA and VGA\\nsignals. Using a whole PC to do this takes up too much space on my bench, and\\nis somewhat less than portable. I guess I could sit down and design something,\\nbut I don't have the time right now - any (reasonable) suggestions would be\\nappreciated.\\n\\nTNX\\n\\nTG</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2785</th>\n",
       "      <td>Hi all,\\n I've been following this thread about jacob's ladder for a few weeks and I\\nhappened to come across one of the best project books that I've seen in a \\nwhile.  The book \"Gadgeteer's Goldmine\" by Gordon McComb offers over 55 \\nexcellent low cost projects including: Jacob's Ladder, tesla coils, plasma \\nspheres, a Van de Graaff generator, robots, an IR scope, and several laser \\nprojects.  The instructions come with complete part lists, warnings and \\ndiagrams.  For those of you who are interested in building any of the above \\nlisted projects, you should seriously consider getting this book.  The \\npaperback version is only $19.95 too.\\n\\nFor those who want more information:\\nTitle: Gadgeteer's Goldmine!  55 Space-Age Projects\\nAuth:  Gordon McComb\\nPub:   TAB Books\\nCW:    1990\\nISBN:  0-8306-8360-7\\n\\t0-8306-3360-X (paperback)\\n Price: $19.95 (paperback)\\n\\n -Scott</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2786</th>\n",
       "      <td>\\n\\nPreliminary data regarding similar research into kangaroo overpopulation\\nin Australia do not in any way support the cost-effectiveness of this\\napproach.  It _may_ be cost-effective for deer--if you quietly overlook\\nthe fact that the net cost to the state of deer hunting is _negative_\\n(i.e. a profit) because the (majority of) hunters pay for licences.\\nThe cost comparisons are probably being done assuming that people have\\nto be employed to cull the animals, which is not in fact the case.\\nYou figure people are going to pay for licences to implant contraceptive\\npellets or spread baits?\\n\\nThere has been a fair bit of discussion about this here recently,\\nbecause the kangaroo population in the grounds of the Governor-\\nGeneral's residence has now reached plague proportions.  Despite the\\nwhines of the rampant animal-libbers, the most effective method of\\ncontrolling the population is still considered to be controlled\\nshooting.\\n\\n\\nSome people take satisfaction (IMHO, legitimate satisfaction) in eating\\nfood that they have harvested themselves.  The pleasure derived from\\nhunting is the same as that you get from eating fruit and vegetables\\ngrown in your own garden (and, in general, game meat is probably much \\nfreer of unpleasant chemicals than what you buy from the butcher or\\nthe supermarket).\\n\\n\\nBy \"cannot now be justified\" I guess you mean that you personally\\ndon't see any justification.  Fine--but what makes your opinion\\nso important?\\n\\n\\nCertainly the last point is correct.  If politicians don't see any\\nvotes for themselves in opposing stupid legislation or in developing\\nand supporting measures which might be effective in reducing the \\nincidence of violent crime they won't do these things.</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2787</th>\n",
       "      <td>Are there any vendors supporting pressure sensitive tablet/pen with X? I\\nwill appreciate any pointers.\\n\\nThanks, Sanjay\\n</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               news  \\\n",
       "2783                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \\nI used a bunch as weights, when building a model airplane.  Hung them\\non the stringers, across the stringer, or whatever.  Worked pretty well.   \n",
       "2784                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    I repair a lot of monitors here, and I'd like to know where I can get a\\npattern generator (or a circuit for one) that will provide MDA, EGA and VGA\\nsignals. Using a whole PC to do this takes up too much space on my bench, and\\nis somewhat less than portable. I guess I could sit down and design something,\\nbut I don't have the time right now - any (reasonable) suggestions would be\\nappreciated.\\n\\nTNX\\n\\nTG   \n",
       "2785                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Hi all,\\n I've been following this thread about jacob's ladder for a few weeks and I\\nhappened to come across one of the best project books that I've seen in a \\nwhile.  The book \"Gadgeteer's Goldmine\" by Gordon McComb offers over 55 \\nexcellent low cost projects including: Jacob's Ladder, tesla coils, plasma \\nspheres, a Van de Graaff generator, robots, an IR scope, and several laser \\nprojects.  The instructions come with complete part lists, warnings and \\ndiagrams.  For those of you who are interested in building any of the above \\nlisted projects, you should seriously consider getting this book.  The \\npaperback version is only $19.95 too.\\n\\nFor those who want more information:\\nTitle: Gadgeteer's Goldmine!  55 Space-Age Projects\\nAuth:  Gordon McComb\\nPub:   TAB Books\\nCW:    1990\\nISBN:  0-8306-8360-7\\n\\t0-8306-3360-X (paperback)\\n Price: $19.95 (paperback)\\n\\n -Scott   \n",
       "2786  \\n\\nPreliminary data regarding similar research into kangaroo overpopulation\\nin Australia do not in any way support the cost-effectiveness of this\\napproach.  It _may_ be cost-effective for deer--if you quietly overlook\\nthe fact that the net cost to the state of deer hunting is _negative_\\n(i.e. a profit) because the (majority of) hunters pay for licences.\\nThe cost comparisons are probably being done assuming that people have\\nto be employed to cull the animals, which is not in fact the case.\\nYou figure people are going to pay for licences to implant contraceptive\\npellets or spread baits?\\n\\nThere has been a fair bit of discussion about this here recently,\\nbecause the kangaroo population in the grounds of the Governor-\\nGeneral's residence has now reached plague proportions.  Despite the\\nwhines of the rampant animal-libbers, the most effective method of\\ncontrolling the population is still considered to be controlled\\nshooting.\\n\\n\\nSome people take satisfaction (IMHO, legitimate satisfaction) in eating\\nfood that they have harvested themselves.  The pleasure derived from\\nhunting is the same as that you get from eating fruit and vegetables\\ngrown in your own garden (and, in general, game meat is probably much \\nfreer of unpleasant chemicals than what you buy from the butcher or\\nthe supermarket).\\n\\n\\nBy \"cannot now be justified\" I guess you mean that you personally\\ndon't see any justification.  Fine--but what makes your opinion\\nso important?\\n\\n\\nCertainly the last point is correct.  If politicians don't see any\\nvotes for themselves in opposing stupid legislation or in developing\\nand supporting measures which might be effective in reducing the \\nincidence of violent crime they won't do these things.   \n",
       "2787                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Are there any vendors supporting pressure sensitive tablet/pen with X? I\\nwill appreciate any pointers.\\n\\nThanks, Sanjay\\n   \n",
       "\n",
       "      target  \n",
       "2783       3  \n",
       "2784       3  \n",
       "2785       3  \n",
       "2786       4  \n",
       "2787       2  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data[\"data\"],columns=[\"news\"])\n",
    "df[\"target\"] = data[\"target\"]\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68f3ae9-1702-4acd-9781-76293730344c",
   "metadata": {},
   "source": [
    "## 워드 임베딩\n",
    "<pre>\n",
    " 희소행렬              밀집행렬\n",
    "-----------------    -----------------\n",
    "원핫인코딩            차수로 차원 축소\n",
    "0 1 의값             분산최대화 투영 행렬내적 : float값\n",
    "벡터의크기=voca_size  dim(차수) 크기의 voca_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da5408fa-5722-462a-a971-e3f55d7934f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2788, 31838),\n",
       " 31838,\n",
       " (2788, 2),\n",
       " [('ýé', 31837),\n",
       "  ('³ation', 31836),\n",
       "  ('zz_g9q3', 31835),\n",
       "  ('zz', 31834),\n",
       "  ('zyxel', 31833)])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "vector = CountVectorizer()                       # 패딩할 필요없다!!!\n",
    "encoded = vector.fit_transform(df['news']).toarray() # 밀집행렬 >> 희소행렬\n",
    "vocab = vector.vocabulary_\n",
    "# vocab.values()==1\n",
    "vocab_sorted = sorted(vector.vocabulary_.items(), key = lambda x:x[1], reverse = True)\n",
    "\n",
    "encoded.shape, len(vocab), df.shape, vocab_sorted[:5]\n",
    "# print('vocabulary :',vector.vocabulary_) \n",
    "# print(len(bag))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650738de-5f71-49a3-909e-667b44c0e604",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 임베딩길이\n",
    "* map(function, iterable)  >> iterable을 function 적용해줘\n",
    "* list(map(int,[1.1,2.2,3.3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30d604ce-ac61-469a-a7e8-26ad593bedd1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(len, [[1,2],[3,4,5]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1249313-64d5-4138-9ff0-b90489e25530",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31838"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length = max(len(x) for x in encoded )\n",
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae74cebc-0d5a-471f-b263-85c07ecda30a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2788"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "41377369-24e8-4650-8d13-9e99ed8b1435",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "169.51470588235293"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(list(map(sum, encoded)))/( len(df) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36e951d9-981a-40c6-8df1-6df786d612c8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31838"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "token = Tokenizer()\n",
    "token.fit_on_texts(df[\"news\"])\n",
    "text_seq_list = token.texts_to_sequences(df[\"news\"])\n",
    "word_cnt = token.word_counts\n",
    "word_idx=token.word_index\n",
    "doc_cnt = token.word_docs\n",
    "max_length = max(len(x) for x in encoded )\n",
    "max_length\n",
    "# list(word_cnt)[:5], list(word_idx)[:5], list(doc_cnt)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "74f71bb3-65a6-49b2-a79f-38a41e2a73bd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'the': 1, 'to': 2}\n",
      "{'the': 1, 'to': 2}\n"
     ]
    }
   ],
   "source": [
    "# dict 슬라이싱\n",
    "import itertools \n",
    "res = dict(itertools.islice(word_idx.items(), 2))\n",
    "print(res)\n",
    "res = dict( list(word_idx.items())[:2] )\n",
    "print(res)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b196e3-2c67-4956-915d-f591282292a8",
   "metadata": {},
   "source": [
    "## Word2vec\n",
    "* 단어단어간의 유사도"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba2febe-f55d-42dc-b0f0-136fae4297cb",
   "metadata": {},
   "source": [
    "## Glove\n",
    "* 카운트기반 + 확률(유사도)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0065957-3969-4b41-b437-66080ae0d03c",
   "metadata": {},
   "source": [
    "## Elmo\n",
    "* 사전 훈련된 사전 데이터를 이용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2082a569-46db-41e3-9df4-e787dd8ecbde",
   "metadata": {},
   "source": [
    "## train test 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb97aee5-7cba-41bc-a982-a58ddfa6bd42",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2788 entries, 0 to 2787\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   news    2788 non-null   object\n",
      " 1   target  2788 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 43.7+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((2788, 2), None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape, df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98829fbb-54f4-4df7-87ef-0e7187dad29f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2788, 31838), numpy.ndarray)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padding_res = pad_sequences(sequences=text_seq_list,   \n",
    "                   maxlen=max_length,      \n",
    "                   padding=\"pre\" \n",
    "                  )\n",
    "padding_res[:5]\n",
    "padding_res.shape, type(padding_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9bddaa72-ddee-44bc-8301-cedac981073b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2788 entries, 0 to 2787\n",
      "Columns: 31838 entries, 0 to 31837\n",
      "dtypes: int32(31838)\n",
      "memory usage: 338.6 MB\n"
     ]
    }
   ],
   "source": [
    "padding_df = pd.DataFrame(padding_res)\n",
    "padding_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "649edc71-3209-4335-9553-c5406e1500dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6c01be9e-4f43-4c81-b1ed-f055acce034f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2230, 31838), (558, 31838), (2230,), (558,))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=df[\"target\"]\n",
    "X=padding_res\n",
    "X_train,X_test,y_train,y_test=train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "X_train.shape,X_test.shape,y_train.shape,y_test.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3fd096-952f-4fc2-9fae-0fb09d746cdd",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 모델학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ff3de48f-b8ab-43ed-97d2-14c517e9d909",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2    593\n",
      "3    591\n",
      "1    578\n",
      "4    546\n",
      "0    480\n",
      "Name: target, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(  df[\"target\"].value_counts()   )\n",
    "\n",
    "df[\"target\"].value_counts().plot(kind = 'bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6923933a-344e-4478-a090-a0cb2c07d23c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 분류모델"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15881e8c-cde9-4ab3-8904-88710f28333d",
   "metadata": {},
   "source": [
    "### RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d6692d85-d4a2-45b8-911d-b78414a2f68a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bc08ae1d-0d7d-4d38-974c-e93407d77156",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24551971326164876"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cf = RandomForestClassifier()\n",
    "cf.fit(X_train,y_train)\n",
    "pred = cf.predict(X_test)\n",
    "sc = accuracy_score(y_test, pred)\n",
    "sc  ## tokenizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8194c348-addf-4a4a-a2a5-7f0cb5b27b5d",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "206a668b-7d6c-4a7f-bb74-18dafd448d64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Dropout, Conv1D, GlobalMaxPooling1D, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4692de-ae0d-44aa-9ae0-8f5c0e5e3fa6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Callback 설정\n",
    "ref : https://keras.io/api/callbacks/<br>  \n",
    "<font color=black>* callback 기능 : Usage of callbacks via the built-in fit() loop <br>\n",
    "  <font color=black>* Write TensorBoard logs after every batch of training to monitor your metrics <br>\n",
    "  <font color=red>* Periodically save your model to disk  ----------------- 모델저장 <br>\n",
    "  <font color=red>* Do early stopping   ----------------------------------- 오버피팅 시 조기종료 <br>\n",
    "  <font color=black>* Get a view on internal states and statistics of a model during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8205fc21-0975-4072-96d3-73f23035c15a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 모델 저장 폴더\n",
    "import os\n",
    "if not os.path.exists(\"./model\"):\n",
    "    os.mkdir('./model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "de6da231-579d-4e94-ae35-baa738039b07",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stopping = EarlyStopping(patience=3),          #------------PATIENCE__ : 조기종료\n",
    "ckpoint  = ModelCheckpoint(filepath='./model/mymodel_{epoch:02d}_{val_loss:.4f}.h5',\n",
    "                monitor='val_loss',          #------------어떤 점수를 기준으로 모니터링할까\n",
    "                save_best_only=True,         #------------이전보다 좋아질때만 저장\n",
    "                save_weights_only=False      #------------모델+가중치 같이 저장\n",
    "               )  # 이전 epoch 점수보다 현재 점수가 좋으면 모델 저장 : mymodel_03_2417.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1e841964-b1d1-4a21-ada8-80bba6e286db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'sequential_1/embedding_1/embedding_lookup' defined at (most recent call last):\n    File \"C:\\AI\\Python38\\lib\\runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\AI\\Python38\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"C:\\AI\\pythonProject\\venv\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\AI\\pythonProject\\venv\\lib\\site-packages\\traitlets\\config\\application.py\", line 1043, in launch_instance\n      app.start()\n    File \"C:\\AI\\pythonProject\\venv\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 728, in start\n      self.io_loop.start()\n    File \"C:\\AI\\pythonProject\\venv\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\AI\\Python38\\lib\\asyncio\\base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"C:\\AI\\Python38\\lib\\asyncio\\base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"C:\\AI\\Python38\\lib\\asyncio\\events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\AI\\pythonProject\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 513, in dispatch_queue\n      await self.process_one()\n    File \"C:\\AI\\pythonProject\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 502, in process_one\n      await dispatch(*args)\n    File \"C:\\AI\\pythonProject\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 409, in dispatch_shell\n      await result\n    File \"C:\\AI\\pythonProject\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"C:\\AI\\pythonProject\\venv\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 423, in do_execute\n      res = shell.run_cell(\n    File \"C:\\AI\\pythonProject\\venv\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\AI\\pythonProject\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2945, in run_cell\n      result = self._run_cell(\n    File \"C:\\AI\\pythonProject\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3000, in _run_cell\n      return runner(coro)\n    File \"C:\\AI\\pythonProject\\venv\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\AI\\pythonProject\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3203, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\AI\\pythonProject\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3382, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\AI\\pythonProject\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3442, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\ASIA\\AppData\\Local\\Temp\\ipykernel_1628\\4067364890.py\", line 15, in <module>\n      history = model.fit(X_train, y_train, epochs=20, validation_data=(X_test, y_test), callbacks=[stopping, ckpoint])  ## callback 중간에 멈추기\n    File \"C:\\AI\\pythonProject\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\AI\\pythonProject\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1650, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\AI\\pythonProject\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in train_function\n      return step_function(self, iterator)\n    File \"C:\\AI\\pythonProject\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1233, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\AI\\pythonProject\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1222, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\AI\\pythonProject\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1023, in train_step\n      y_pred = self(x, training=True)\n    File \"C:\\AI\\pythonProject\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\AI\\pythonProject\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 561, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"C:\\AI\\pythonProject\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\AI\\pythonProject\\venv\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\AI\\pythonProject\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\AI\\pythonProject\\venv\\lib\\site-packages\\keras\\engine\\sequential.py\", line 413, in call\n      return super().call(inputs, training=training, mask=mask)\n    File \"C:\\AI\\pythonProject\\venv\\lib\\site-packages\\keras\\engine\\functional.py\", line 511, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"C:\\AI\\pythonProject\\venv\\lib\\site-packages\\keras\\engine\\functional.py\", line 668, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"C:\\AI\\pythonProject\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\AI\\pythonProject\\venv\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\AI\\pythonProject\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\AI\\pythonProject\\venv\\lib\\site-packages\\keras\\layers\\core\\embedding.py\", line 208, in call\n      out = tf.nn.embedding_lookup(self.embeddings, inputs)\nNode: 'sequential_1/embedding_1/embedding_lookup'\nindices[14,31722] = 32157 is not in [0, 31838)\n\t [[{{node sequential_1/embedding_1/embedding_lookup}}]] [Op:__inference_train_function_2551]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m ckpoint \u001b[38;5;241m=\u001b[39m ModelCheckpoint(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_model.h5\u001b[39m\u001b[38;5;124m'\u001b[39m, monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m'\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     14\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124macc\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m---> 15\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mstopping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpoint\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m## callback 중간에 멈추기\u001b[39;00m\n",
      "File \u001b[1;32mC:\\AI\\pythonProject\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mC:\\AI\\pythonProject\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'sequential_1/embedding_1/embedding_lookup' defined at (most recent call last):\n    File \"C:\\AI\\Python38\\lib\\runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\AI\\Python38\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"C:\\AI\\pythonProject\\venv\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\AI\\pythonProject\\venv\\lib\\site-packages\\traitlets\\config\\application.py\", line 1043, in launch_instance\n      app.start()\n    File \"C:\\AI\\pythonProject\\venv\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 728, in start\n      self.io_loop.start()\n    File \"C:\\AI\\pythonProject\\venv\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\AI\\Python38\\lib\\asyncio\\base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"C:\\AI\\Python38\\lib\\asyncio\\base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"C:\\AI\\Python38\\lib\\asyncio\\events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\AI\\pythonProject\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 513, in dispatch_queue\n      await self.process_one()\n    File \"C:\\AI\\pythonProject\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 502, in process_one\n      await dispatch(*args)\n    File \"C:\\AI\\pythonProject\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 409, in dispatch_shell\n      await result\n    File \"C:\\AI\\pythonProject\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"C:\\AI\\pythonProject\\venv\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 423, in do_execute\n      res = shell.run_cell(\n    File \"C:\\AI\\pythonProject\\venv\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\AI\\pythonProject\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2945, in run_cell\n      result = self._run_cell(\n    File \"C:\\AI\\pythonProject\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3000, in _run_cell\n      return runner(coro)\n    File \"C:\\AI\\pythonProject\\venv\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\AI\\pythonProject\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3203, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\AI\\pythonProject\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3382, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\AI\\pythonProject\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3442, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\ASIA\\AppData\\Local\\Temp\\ipykernel_1628\\4067364890.py\", line 15, in <module>\n      history = model.fit(X_train, y_train, epochs=20, validation_data=(X_test, y_test), callbacks=[stopping, ckpoint])  ## callback 중간에 멈추기\n    File \"C:\\AI\\pythonProject\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\AI\\pythonProject\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1650, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\AI\\pythonProject\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in train_function\n      return step_function(self, iterator)\n    File \"C:\\AI\\pythonProject\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1233, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\AI\\pythonProject\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1222, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\AI\\pythonProject\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1023, in train_step\n      y_pred = self(x, training=True)\n    File \"C:\\AI\\pythonProject\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\AI\\pythonProject\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 561, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"C:\\AI\\pythonProject\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\AI\\pythonProject\\venv\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\AI\\pythonProject\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\AI\\pythonProject\\venv\\lib\\site-packages\\keras\\engine\\sequential.py\", line 413, in call\n      return super().call(inputs, training=training, mask=mask)\n    File \"C:\\AI\\pythonProject\\venv\\lib\\site-packages\\keras\\engine\\functional.py\", line 511, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"C:\\AI\\pythonProject\\venv\\lib\\site-packages\\keras\\engine\\functional.py\", line 668, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"C:\\AI\\pythonProject\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\AI\\pythonProject\\venv\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\AI\\pythonProject\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\AI\\pythonProject\\venv\\lib\\site-packages\\keras\\layers\\core\\embedding.py\", line 208, in call\n      out = tf.nn.embedding_lookup(self.embeddings, inputs)\nNode: 'sequential_1/embedding_1/embedding_lookup'\nindices[14,31722] = 32157 is not in [0, 31838)\n\t [[{{node sequential_1/embedding_1/embedding_lookup}}]] [Op:__inference_train_function_2551]"
     ]
    }
   ],
   "source": [
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(vocab), 100))  ## 밀집행렬 차원축소\n",
    "#----------------------------CNN 1D-------------------------------------------\n",
    "model.add(Conv1D(260, 3, padding='valid', activation='relu'))\n",
    "# model.add(Dropout(0.3))\n",
    "model.add(GlobalMaxPooling1D())  \n",
    "model.add(Dense(56, activation='relu'))\n",
    "# model.add(Dropout(0.3))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "stopping = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=3)\n",
    "ckpoint = ModelCheckpoint('best_model.h5', monitor='val_loss', mode='min', verbose=1, save_best_only=True)\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['acc'])\n",
    "# history = model.fit(X_train, y_train, epochs=20, validation_data=(X_test, y_test), callbacks=[stopping, ckpoint])  ## callback 중간에 멈추기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82385321-13f8-4ac3-9da9-561c5a99057c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,3))\n",
    "ax1 = plt.subplot(1,2,1)\n",
    "ax1.plot(fit_hisroty.history['loss']    , label='loss')\n",
    "ax1.plot(fit_hisroty.history['val_loss'], label='val_loss')\n",
    "ax1.legend()\n",
    "ax1.set_title(\"loss\")\n",
    "\n",
    "ax2 = plt.subplot(1,2,2)\n",
    "ax2.plot(fit_hisroty.history['accuracy']    , label='accuracy')\n",
    "ax2.plot(fit_hisroty.history['val_accuracy'], label='val_accuracy')\n",
    "ax2.legend()\n",
    "ax2.set_title(\"accuracy\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed0e127-3f2d-499c-a794-fd8645c3cfbb",
   "metadata": {},
   "source": [
    "### CNN + RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6494286d-65ee-4ef1-a58e-a4f46d06c51a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5804b8-fe0b-4335-8eb6-65e0a9561c02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d8f5fd-40d8-48e0-a7a9-16d19cfdb962",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a9ebd739-2dd2-40ac-9a2f-ff61627a0671",
   "metadata": {},
   "source": [
    "### RNN(LSTM, BiLSTM GRU)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
