{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from xgboost import XGBClassifier\n",
    "import optuna\n",
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data consist of the estimation of obesity levels in people from the countries of Mexico, Peru and Colombia, with ages between 14 and 61 and diverse eating habits and physical condition , data was collected using a web platform with a survey where anonymous users answered each question, then the information was processed obtaining 17 attributes and 2111 records.\n",
    "The attributes related with eating habits are:  \n",
    "Frequent consumption of high caloric food (FAVC)  \n",
    "Frequency of consumption of vegetables (FCVC)  \n",
    "Number of main meals (NCP)  \n",
    "Consumption of food between meals (CAEC)  \n",
    "Consumption of water daily (CH20)  \n",
    "and Consumption of alcohol (CALC)  \n",
    "The attributes related with the physical condition are:  \n",
    "Calories consumption monitoring (SCC)  \n",
    "Physical activity frequency (FAF)  \n",
    "Time using technology devices (TUE)  \n",
    "Transportation used (MTRANS)  \n",
    "\n",
    "variables obtained :\n",
    "Gender, Age, Height and Weight.\n",
    "\n",
    "NObesity values are:  \n",
    "\n",
    "•Underweight Less than 18.5  \n",
    "\n",
    "•Normal 18.5 to 24.9  \n",
    "\n",
    "•Overweight 25.0 to 29.9  \n",
    "\n",
    "•Obesity I 30.0 to 34.9  \n",
    "\n",
    "•Obesity II 35.0 to 39.9  \n",
    "\n",
    "•Obesity III Higher than 40  \n",
    "\n",
    "\n",
    "The data contains numerical data and continous data, so it can be used for analysis based on algorithms of classification, prediction, segmentation and association. Data is available in CSV format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA LOAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>family_history_with_overweight</th>\n",
       "      <th>FAVC</th>\n",
       "      <th>FCVC</th>\n",
       "      <th>NCP</th>\n",
       "      <th>CAEC</th>\n",
       "      <th>SMOKE</th>\n",
       "      <th>CH2O</th>\n",
       "      <th>SCC</th>\n",
       "      <th>FAF</th>\n",
       "      <th>TUE</th>\n",
       "      <th>CALC</th>\n",
       "      <th>MTRANS</th>\n",
       "      <th>NObeyesdad</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Male</td>\n",
       "      <td>24.443011</td>\n",
       "      <td>1.699998</td>\n",
       "      <td>81.669950</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.983297</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.763573</td>\n",
       "      <td>no</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.976473</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Overweight_Level_II</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Female</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.560000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>Frequently</td>\n",
       "      <td>no</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>no</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>no</td>\n",
       "      <td>Automobile</td>\n",
       "      <td>Normal_Weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Female</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.711460</td>\n",
       "      <td>50.165754</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.880534</td>\n",
       "      <td>1.411685</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>1.910378</td>\n",
       "      <td>no</td>\n",
       "      <td>0.866045</td>\n",
       "      <td>1.673584</td>\n",
       "      <td>no</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Insufficient_Weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Female</td>\n",
       "      <td>20.952737</td>\n",
       "      <td>1.710730</td>\n",
       "      <td>131.274851</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>1.674061</td>\n",
       "      <td>no</td>\n",
       "      <td>1.467863</td>\n",
       "      <td>0.780199</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Obesity_Type_III</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Male</td>\n",
       "      <td>31.641081</td>\n",
       "      <td>1.914186</td>\n",
       "      <td>93.798055</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>2.679664</td>\n",
       "      <td>1.971472</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>1.979848</td>\n",
       "      <td>no</td>\n",
       "      <td>1.967973</td>\n",
       "      <td>0.931721</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Overweight_Level_II</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Gender        Age    Height      Weight family_history_with_overweight  \\\n",
       "id                                                                           \n",
       "0     Male  24.443011  1.699998   81.669950                            yes   \n",
       "1   Female  18.000000  1.560000   57.000000                            yes   \n",
       "2   Female  18.000000  1.711460   50.165754                            yes   \n",
       "3   Female  20.952737  1.710730  131.274851                            yes   \n",
       "4     Male  31.641081  1.914186   93.798055                            yes   \n",
       "\n",
       "   FAVC      FCVC       NCP        CAEC SMOKE      CH2O SCC       FAF  \\\n",
       "id                                                                      \n",
       "0   yes  2.000000  2.983297   Sometimes    no  2.763573  no  0.000000   \n",
       "1   yes  2.000000  3.000000  Frequently    no  2.000000  no  1.000000   \n",
       "2   yes  1.880534  1.411685   Sometimes    no  1.910378  no  0.866045   \n",
       "3   yes  3.000000  3.000000   Sometimes    no  1.674061  no  1.467863   \n",
       "4   yes  2.679664  1.971472   Sometimes    no  1.979848  no  1.967973   \n",
       "\n",
       "         TUE       CALC                 MTRANS           NObeyesdad  \n",
       "id                                                                   \n",
       "0   0.976473  Sometimes  Public_Transportation  Overweight_Level_II  \n",
       "1   1.000000         no             Automobile        Normal_Weight  \n",
       "2   1.673584         no  Public_Transportation  Insufficient_Weight  \n",
       "3   0.780199  Sometimes  Public_Transportation     Obesity_Type_III  \n",
       "4   0.931721  Sometimes  Public_Transportation  Overweight_Level_II  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('./datasets/train.csv', index_col=0)\n",
    "test = pd.read_csv(\"./datasets/test.csv\", index_col=0)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>FCVC</th>\n",
       "      <th>NCP</th>\n",
       "      <th>CH2O</th>\n",
       "      <th>FAF</th>\n",
       "      <th>TUE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24.443011</td>\n",
       "      <td>1.699998</td>\n",
       "      <td>81.66995</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.983297</td>\n",
       "      <td>2.763573</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.976473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.560000</td>\n",
       "      <td>57.00000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Age    Height    Weight  FCVC       NCP      CH2O  FAF       TUE\n",
       "id                                                                        \n",
       "0   24.443011  1.699998  81.66995   2.0  2.983297  2.763573  0.0  0.976473\n",
       "1   18.000000  1.560000  57.00000   2.0  3.000000  2.000000  1.0  1.000000"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = train.drop('NObeyesdad', axis=1)\n",
    "labels = pd.DataFrame(train['NObeyesdad'])\n",
    "\n",
    "# 연속형 피쳐\n",
    "mask_numeric = features.dtypes == float\n",
    "df_numerical = features.loc[:, mask_numeric]\n",
    "\n",
    "df_numerical.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender\n",
      "Female    10422\n",
      "Male      10336\n",
      "Name: count, dtype: int64\n",
      "family_history_with_overweight\n",
      "yes    17014\n",
      "no      3744\n",
      "Name: count, dtype: int64\n",
      "FAVC\n",
      "yes    18982\n",
      "no      1776\n",
      "Name: count, dtype: int64\n",
      "CAEC\n",
      "Sometimes     17529\n",
      "Frequently     2472\n",
      "Always          478\n",
      "no              279\n",
      "Name: count, dtype: int64\n",
      "SMOKE\n",
      "no     20513\n",
      "yes      245\n",
      "Name: count, dtype: int64\n",
      "SCC\n",
      "no     20071\n",
      "yes      687\n",
      "Name: count, dtype: int64\n",
      "CALC\n",
      "Sometimes     15066\n",
      "no             5163\n",
      "Frequently      529\n",
      "Name: count, dtype: int64\n",
      "MTRANS\n",
      "Public_Transportation    16687\n",
      "Automobile                3534\n",
      "Walking                    467\n",
      "Motorbike                   38\n",
      "Bike                        32\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 카테고리형 피쳐\n",
    "mask_categorical = features.dtypes != float\n",
    "df_categorical = features.loc[:, mask_categorical]\n",
    "\n",
    "for i in range(df_categorical.shape[1]):\n",
    "    print(df_categorical.iloc[:, i].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded = df_categorical.copy(deep=True)\n",
    "\n",
    "# label encoding\n",
    "df_encoded['Gender'] = df_categorical['Gender'].map({'Male':0, 'Female':1})\n",
    "df_encoded['family_history_with_overweight'] = df_categorical['family_history_with_overweight'].map({'no':0, 'yes':1})\n",
    "df_encoded['FAVC'] = df_categorical['FAVC'].map({'no':0, 'yes':1})\n",
    "df_encoded['CAEC'] = df_categorical['CAEC'].map({'no':0, 'Sometimes':1, 'Frequently':2, 'Always':3})\n",
    "df_encoded['SMOKE'] = df_categorical['SMOKE'].map({'no':0, 'yes':1})\n",
    "df_encoded['SCC'] = df_categorical['SCC'].map({'no':0, 'yes':1})\n",
    "df_encoded['CALC'] = df_categorical['CALC'].map({'no':0, 'Sometimes':1, 'Frequently':2, 'Always':3})\n",
    "\n",
    "# one-hot encoding\n",
    "df_onehot = pd.get_dummies(df_categorical['MTRANS']).astype(int)\n",
    "df_encoded.drop('MTRANS', axis=1, inplace=True)\n",
    "\n",
    "# concatenate\n",
    "# one feature of df_encoded is redundant; we can remove it\n",
    "df_encoded = pd.concat([df_encoded, df_onehot.iloc[:, 0:-1]], axis=1)\n",
    "\n",
    "#df_encoded\n",
    "df_all_features = pd.concat([df_numerical, df_encoded], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_preprocessing(data):\n",
    "    features = data.copy(deep=True)\n",
    "\n",
    "    # numerical dataframe\n",
    "    mask_numeric = features.dtypes == float\n",
    "    df_numerical = features.loc[:, mask_numeric]\n",
    "\n",
    "    # categorical dataframe\n",
    "    mask_categorical = features.dtypes != float\n",
    "    df_categorical = features.loc[:, mask_categorical]\n",
    "\n",
    "    # label encoding\n",
    "    df_encoded = df_categorical.copy(deep=True)\n",
    "    df_encoded['Gender'] = df_categorical['Gender'].map({'Male':0, 'Female':1})\n",
    "    df_encoded['family_history_with_overweight'] = df_categorical['family_history_with_overweight'].map({'no':0, 'yes':1})\n",
    "    df_encoded['FAVC'] = df_categorical['FAVC'].map({'no':0, 'yes':1})\n",
    "    df_encoded['CAEC'] = df_categorical['CAEC'].map({'no':0, 'Sometimes':1, 'Frequently':2, 'Always':3})\n",
    "    df_encoded['SMOKE'] = df_categorical['SMOKE'].map({'no':0, 'yes':1})\n",
    "    df_encoded['SCC'] = df_categorical['SCC'].map({'no':0, 'yes':1})\n",
    "    df_encoded['CALC'] = df_categorical['CALC'].map({'no':0, 'Sometimes':1, 'Frequently':2, 'Always':3})\n",
    "\n",
    "    # one-hot encoding\n",
    "    df_onehot = pd.get_dummies(df_categorical['MTRANS']).astype(int)\n",
    "    df_encoded.drop('MTRANS', axis=1, inplace=True)\n",
    "\n",
    "    # concatenate\n",
    "    # one feature of df_encoded is redundant; we can remove it\n",
    "    df_encoded = pd.concat([df_encoded, df_onehot.iloc[:, 0:-1]], axis=1)\n",
    "\n",
    "    df_all_features = pd.concat([df_numerical, df_encoded], axis=1)\n",
    "\n",
    "    return df_all_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train columns Index(['Age', 'Height', 'Weight', 'FCVC', 'NCP', 'CH2O', 'FAF', 'TUE',\n",
      "       'Gender', 'family_history_with_overweight', 'FAVC', 'CAEC', 'SMOKE',\n",
      "       'SCC', 'CALC', 'Automobile', 'Bike', 'Motorbike',\n",
      "       'Public_Transportation'],\n",
      "      dtype='object')\n",
      "Test columns Index(['Age', 'Height', 'Weight', 'FCVC', 'NCP', 'CH2O', 'FAF', 'TUE',\n",
      "       'Gender', 'family_history_with_overweight', 'FAVC', 'CAEC', 'SMOKE',\n",
      "       'SCC', 'CALC', 'Automobile', 'Bike', 'Motorbike',\n",
      "       'Public_Transportation'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "test = apply_preprocessing(test)\n",
    "\n",
    "print('Train columns', df_all_features.columns)\n",
    "print('Test columns', test.columns)\n",
    "\n",
    "assert all(test.columns ==  df_all_features.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels_encoded\n",
    "labels['NObeyesdad'].unique()\n",
    "\n",
    "labels_encoded = labels.copy(deep=True)\n",
    "\n",
    "dict_conversion = {'Insufficient_Weight':0,\n",
    "                   'Normal_Weight':1,\n",
    "                   'Overweight_Level_I':2,\n",
    "                   'Overweight_Level_II':3,\n",
    "                   'Obesity_Type_I':4,\n",
    "                   'Obesity_Type_II':5,\n",
    "                   'Obesity_Type_III':6}\n",
    "\n",
    "labels_encoded['NObeyesdad'] = labels_encoded['NObeyesdad'].map(dict_conversion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20758, 1)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_encoded.shape\n",
    "# (20758, 1) / DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20758,)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape\n",
    "# (20758,) / ARRAY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples 20758\n",
      "Number of featires 19\n"
     ]
    }
   ],
   "source": [
    "X = df_all_features\n",
    "y = np.ravel(labels_encoded) # flattening\n",
    "\n",
    "# compare train and test data\n",
    "X_test = test\n",
    "assert all(X_test.columns == X.columns), \"Columns of training and test data must be the same\"\n",
    "\n",
    "print('Number of samples', len(X))\n",
    "print('Number of featires', X.shape[1])\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X, y,\n",
    "                                                                test_size=0.2, \n",
    "                                                                random_state=42,\n",
    "                                                                stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "#  class 의 imbalance할 때 class에 따른 가중치를 부여하고 싶을 때 사용한다.\n",
    "\n",
    "# calculate class weights based on the training data\n",
    "class_weights = compute_class_weight('balanced', \n",
    "                                     classes=np.unique(y),\n",
    "                                     y=y)\n",
    "\n",
    "class_weights = dict(zip(np.unique(y), class_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 1.1753581337410113,\n",
       " 1: 0.962176694168907,\n",
       " 2: 1.2218494319854023,\n",
       " 3: 1.1758241758241759,\n",
       " 4: 1.019047619047619,\n",
       " 5: 0.9130014074595355,\n",
       " 6: 0.7329284655038486}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREDICTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004606 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2047\n",
      "[LightGBM] [Info] Number of data points in the train set: 16606, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -1.945910\n",
      "[LightGBM] [Info] Start training from score -1.945910\n",
      "[LightGBM] [Info] Start training from score -1.945910\n",
      "[LightGBM] [Info] Start training from score -1.945910\n",
      "[LightGBM] [Info] Start training from score -1.945910\n",
      "[LightGBM] [Info] Start training from score -1.945910\n",
      "[LightGBM] [Info] Start training from score -1.945910\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, objective=&#x27;multi:softprob&#x27;, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, objective=&#x27;multi:softprob&#x27;, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, objective='multi:softprob', ...)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_GB = GradientBoostingClassifier()\n",
    "clf_RF = RandomForestClassifier(class_weight='balanced')\n",
    "clf_LGBM = LGBMClassifier(class_weight='balanced')\n",
    "clf_XGB = XGBClassifier()\n",
    "\n",
    "clf_GB.fit(X_train, y_train)\n",
    "clf_RF.fit(X_train, y_train)\n",
    "clf_LGBM.fit(X_train, y_train)\n",
    "clf_XGB.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(clf):\n",
    "    y_pred_train = clf.predict(X_train)\n",
    "    y_pred_test = clf.predict(X_validation)\n",
    "    train_score = np.mean(y_pred_train == y_train)\n",
    "    validation_score = np.mean(y_pred_test == y_validation)\n",
    "\n",
    "    print('Train score', round(train_score, 3))\n",
    "    print('Test score', round(validation_score, 3))\n",
    "\n",
    "    if train_score - validation_score > 0.05:\n",
    "        print('Overfitting detected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score 1.0\n",
      "Test score 0.9\n",
      "Overfitting detected\n",
      "\n",
      "\n",
      "LightGBM\n",
      "Train score 0.979\n",
      "Test score 0.905\n",
      "Overfitting detected\n",
      "\n",
      "\n",
      "Gradient Boosting\n",
      "Train score 0.923\n",
      "Test score 0.903\n",
      "\n",
      "\n",
      "XGBoost\n",
      "Train score 0.987\n",
      "Test score 0.905\n",
      "Overfitting detected\n"
     ]
    }
   ],
   "source": [
    "print('Random Forest')\n",
    "evaluate_model(clf_RF)\n",
    "print('\\n')\n",
    "print('LightGBM')\n",
    "evaluate_model(clf_LGBM)\n",
    "print('\\n')\n",
    "print('Gradient Boosting')\n",
    "evaluate_model(clf_GB)\n",
    "print('\\n')\n",
    "print('XGBoost')\n",
    "evaluate_model(clf_XGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    max_depth = trial.suggest_int('max_depth', 4, 10)\n",
    "    n_estimators = trial.suggest_int('n_estimators', 500, 2000)\n",
    "    gamma = trial.suggest_float('gamma', 0, 1)\n",
    "    reg_alpha = trial.suggest_float('reg_alpha', 0, 1)\n",
    "    reg_lambda = trial.suggest_float('reg_lambda', 0, 1)\n",
    "    min_child_weight = trial.suggest_int('min_child_weight', 0, 10)\n",
    "    subsample = trial.suggest_float('subsample', 0, 1)\n",
    "    colsample_bytree = trial.suggest_float('colsample_bytree', 0, 1)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 0, 1)\n",
    "\n",
    "    print('Training the model with', X.shape[1], 'features')\n",
    "\n",
    "    params = {'n_estimators': n_estimators,\n",
    "              'learning_rate': learning_rate,\n",
    "              'gamma': gamma,\n",
    "              'reg_alpha': reg_alpha,\n",
    "              'reg_lambda': reg_lambda,\n",
    "              'max_depth': max_depth,\n",
    "              'min_child_weight': min_child_weight,\n",
    "              'subsample': subsample,\n",
    "              'colsample_bytree': colsample_bytree,\n",
    "              'eval_metric':'mlogloss'}\n",
    "\n",
    "    clf = XGBClassifier(**params)\n",
    "\n",
    "    cv_results = cross_validate(clf, X, y, cv=5, scoring='accuracy')\n",
    "\n",
    "    validation_score = np.mean(cv_results['test_score'])\n",
    "\n",
    "    return validation_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    max_depth = trial.suggest_int('max_depth', 4, 10)\n",
    "    n_estimators = trial.suggest_int('n_estimators', 500, 2000)\n",
    "    gamma = trial.suggest_float('gamma', 0, 1)\n",
    "    reg_alpha = trial.suggest_float('reg_alpha', 0, 1)\n",
    "    reg_lambda = trial.suggest_float('reg_lambda', 0, 1)\n",
    "    min_child_weight = trial.suggest_int('min_child_weight', 0, 10)\n",
    "    subsample = trial.suggest_float('subsample', 0, 1)\n",
    "    colsample_bytree = trial.suggest_float('colsample_bytree', 0, 1)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 0, 1)\n",
    "\n",
    "    print('Training the model with', X.shape[1], 'features')\n",
    "\n",
    "    params = {'n_estimators': n_estimators,\n",
    "              'learning_rate': learning_rate,\n",
    "              'gamma': gamma,\n",
    "              'reg_alpha': reg_alpha,\n",
    "              'reg_lambda': reg_lambda,\n",
    "              'max_depth': max_depth,\n",
    "              'min_child_weight': min_child_weight,\n",
    "              'subsample': subsample,\n",
    "              'colsample_bytree': colsample_bytree,\n",
    "              'eval_metric':'mlogloss'}\n",
    "\n",
    "    clf = XGBClassifier(**params)\n",
    "\n",
    "    cv_results = cross_validate(clf, X, y, cv=5, scoring='accuracy')\n",
    "\n",
    "    validation_score = np.mean(cv_results['test_score'])\n",
    "\n",
    "    return validation_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 10, 'n_estimators': 1224, 'gamma': 0.8323134488556143, 'reg_alpha': 0.9211957174104992, 'reg_lambda': 0.8522905506401445, 'min_child_weight': 4, 'subsample': 0.9232723357974977, 'colsample_bytree': 0.4785000546841373, 'learning_rate': 0.06435693511798936}\n"
     ]
    }
   ],
   "source": [
    "best_params_XGB = {'max_depth': 10, \n",
    "               'n_estimators': 1224, \n",
    "               'gamma': 0.8323134488556143, \n",
    "               'reg_alpha': 0.9211957174104992, \n",
    "               'reg_lambda': 0.8522905506401445, \n",
    "               'min_child_weight': 4, \n",
    "               'subsample': 0.9232723357974977, \n",
    "               'colsample_bytree': 0.4785000546841373, \n",
    "               'learning_rate': 0.06435693511798936}\n",
    "\n",
    "print(best_params_XGB)\n",
    "\n",
    "# Best parameters taken from https://www.kaggle.com/code/ddosad/ps4e2-visual-eda-lgbm/notebook\n",
    "best_params_LGBM = {\n",
    "    \"objective\": \"multiclass\",          # Objective function for the model\n",
    "    \"metric\": \"multi_logloss\",          # Evaluation metric\n",
    "    \"verbosity\": -1,                    # Verbosity level (-1 for silent)\n",
    "    \"boosting_type\": \"gbdt\",            # Gradient boosting type\n",
    "    \"random_state\": 42,       # Random state for reproducibility\n",
    "    \"num_class\": 7,                     # Number of classes in the dataset\n",
    "    'learning_rate': 0.030962211546832760,  # Learning rate for gradient boosting\n",
    "    'n_estimators': 500,                # Number of boosting iterations\n",
    "    'lambda_l1': 0.009667446568254372,  # L1 regularization term\n",
    "    'lambda_l2': 0.04018641437301800,   # L2 regularization term\n",
    "    'max_depth': 10,                    # Maximum depth of the trees\n",
    "    'colsample_bytree': 0.40977129346872643,  # Fraction of features to consider for each tree\n",
    "    'subsample': 0.9535797422450176,    # Fraction of samples to consider for each boosting iteration\n",
    "    'min_child_samples': 26             # Minimum number of data needed in a leaf\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = XGBClassifier(**best_params_XGB)\n",
    "\n",
    "#clf = LGBMClassifier(**best_params_LGBM)\n",
    "\n",
    "clf.fit(X, y)\n",
    "\n",
    "\n",
    "predictions = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>NObeyesdad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20758</td>\n",
       "      <td>Obesity_Type_II</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20759</td>\n",
       "      <td>Overweight_Level_I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20760</td>\n",
       "      <td>Obesity_Type_III</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20761</td>\n",
       "      <td>Obesity_Type_I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20762</td>\n",
       "      <td>Obesity_Type_III</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id          NObeyesdad\n",
       "0  20758     Obesity_Type_II\n",
       "1  20759  Overweight_Level_I\n",
       "2  20760    Obesity_Type_III\n",
       "3  20761      Obesity_Type_I\n",
       "4  20762    Obesity_Type_III"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reverse_dict_conversion = dict(zip(dict_conversion.values(), dict_conversion.keys()))\n",
    "\n",
    "df_submission = pd.read_csv(\"./datasets/sample_submission.csv\")\n",
    "df_submission['NObeyesdad'] = predictions\n",
    "df_submission['NObeyesdad'] = df_submission['NObeyesdad'].map(reverse_dict_conversion)\n",
    "\n",
    "df_submission.to_csv('submission_03.csv', index=False)\n",
    "df_submission.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
