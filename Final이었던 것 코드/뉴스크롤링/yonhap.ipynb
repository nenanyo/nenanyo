{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55f0d2c1-6740-488b-b468-3d9e930513c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7104652444443134"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sqlalchemy as sa\n",
    "import cx_Oracle\n",
    "import xml.etree.ElementTree as ET\n",
    "import json\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "random.uniform(0.2, 1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40e3b28-80f0-4919-b080-c689f3c08bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "<a href=\"//en.yna.co.kr/view/AEN20230424000400315?section=search\" target=\"_blank\">(EDITORIAL from Korea Times on April 24)</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb8c5ba-53ee-4a11-afef-3d4294a8e099",
   "metadata": {},
   "source": [
    "# 리스트 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "150eccaa-d4be-4db2-8fb1-aecf64dfd9cc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASIA\\AppData\\Local\\Temp\\ipykernel_23804\\950477398.py:14: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome('chromedriver_110.exe')\n"
     ]
    }
   ],
   "source": [
    "# pip install selenium\n",
    "# download chrome driver\n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "\n",
    "def mysearch() :\n",
    "\n",
    "    # driver = webdriver.Chrome('chromedriver_110.exe')\n",
    "    # driver.get(\"https://en.yna.co.kr/economy-finance/economy/1\")\n",
    "\n",
    "    #---------------------------------------------- 스크롤 다운\n",
    "    # endkey = 4  # 스크롤 다운 시 12개목록씩 추가  -- 총 12*4=48개\n",
    "    # while endkey:\n",
    "        # driver.find_element_by_tag_name('body').send_keys(Keys.END)\n",
    "        #ele_path = driver.find_element(By.CSS_SELECTOR, \"# __next > div > div.mainContainer_container__1GEbx > div > div > main > div:nth-child(2) > div.guide_GuidePanel__3S6xd > div > div > button\")\n",
    "        ele_path = driver.find_element(By.XPATH, '//*[@id=\"container\"]/section/div/div/a')   \n",
    "        driver.execute_script(\"arguments[0].click();\", ele_path);\n",
    "        time.sleep(2)\n",
    "        endkey -= 1\n",
    "\n",
    "        htmlstr = driver.page_source\n",
    "        soup = BeautifulSoup(htmlstr, features=\"html.parser\")\n",
    "        # \"#__next > div > div.mainContainer_container__1GEbx > div > div > main > div:nth-child(2) > div.guide_GuidePanel__3S6xd > div > ul > li:nth-child(1)\"\n",
    "        div_list = soup.select(\"#container > section > div.sub-content > div.smain-list-type01 > ul > li\")\n",
    "        #----------------------------------------------\n",
    "        # content_list =[]\n",
    "        news_list = []\n",
    "        \n",
    "        for div in div_list: \n",
    "            # tag   = div.select_one(\"#container > section > div.sub-content > div.smain-list-type01 > ul > li > article > div > span.tag\").text\n",
    "            #container > section > div.sub-content > div.smain-list-type01 > ul > li:nth-child(1) > article > div > span.tag\n",
    "            href     = div.select_one(\"#container > section > div.sub-content > div.smain-list-type01 > ul > li > article > div > h2 > a\").get('href')\n",
    "            title   = div.select_one(\"#container > section > div.sub-content > div.smain-list-type01 > ul > li > article > div > h2\").text\n",
    "            content = div.select_one(\"#container > section > div.sub-content > div.smain-list-type01 > ul > li> article > div > span.lead\").text\n",
    "            date = div.select_one(\"#container > section > div.sub-content > div.smain-list-type01 > ul > li > article > div > span.date\").text\n",
    "\n",
    "\n",
    "            news_list.append([title, href,content,date])\n",
    "    df_news = pd.DataFrame(news_list, columns=[\"title\",\"href\",\"content\",\"date\"])\n",
    "    df_news.to_csv(\"./datasets/yonhap.csv\", index=False)\n",
    "    return news_list\n",
    "\n",
    "\n",
    "\n",
    "a=mysearch()\n",
    "# print(len(div_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06313878-d79b-4b4d-84d5-3e9778c29200",
   "metadata": {},
   "outputs": [],
   "source": [
    "//*[@id=\"container\"]/section/div[1]/div[1]/ul/li[1]/article/div/h2/a\n",
    "//*[@id=\"container\"]/section/div[1]/div[1]/ul/li[2]/article/div/h2/a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97a14d3b-fac8-4958-b391-fc6d831ccdcc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73f4a1cf-dec8-4e35-963c-217ac2d19635",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"By Kang Yoon-seung\\nSEOUL, April 28 (Yonhap) -- South Korea's state-run firms saw their debt rise 15 percent on-year in 2022, data showed Friday, led mostly by the Korea Electric Power Corporation (...\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"./datasets/yonhap.csv\")\n",
    "df[\"content\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5aee17-4873-4ced-a005-51d269f4a579",
   "metadata": {},
   "source": [
    "# 원문 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4bce3422-7d6c-42e8-a3b9-58f7dd77ae24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install selenium\n",
    "# download chrome driver\n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "\n",
    "def mysearch() :\n",
    "    #---------------------------------------------- 크롬 옵션 객체 생성\n",
    "    # options = webdriver.ChromeOptions()\n",
    "    # options.add_argument(\"window-size=1000x800\") # 화면크기(전체화면)\n",
    "    # user_agent = \"Mozilla/5.0 (Windows NT 4.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/37.0.2049.0 Safari/537.36 \"\n",
    "    # options.add_argument('user-agent=' + user_agent)\n",
    "    # options.add_argument('headless') # headless 모드 설정\n",
    "    # options.add_argument(\"disable-gpu\")\n",
    "    # options.add_argument(\"disable-infobars\")\n",
    "    # options.add_argument(\"--disable-extensions\")\n",
    "    # options.add_argument(\"--mute-audio\") #mute\n",
    "    # options.add_argument('--blink-settings=imagesEnabled=false') #브라우저에서 이미지 로딩을 하지 않습니다.\n",
    "    # options.add_argument('incognito') #시크릿 모드의 브라우저가 실행됩니다.\n",
    "    # options.add_argument(\"--start-maximized\")\n",
    "    # driver = webdriver.Chrome('./chromedriver_102.0.5005.27.exe', options=options)\n",
    "\n",
    "    # print(\"search_word\", search_word)\n",
    "    #---------------------------------------------- 크롬 드라이버 로드  110.0.5481.177\n",
    "    # https://chromedriver.chromium.org/downloads\n",
    "    # https://chromedriver.storage.googleapis.com/index.html?path=110.0.5481.77/\n",
    "    # ----------------------------------------------\n",
    "    driver = webdriver.Chrome('chromedriver_110.exe')\n",
    "    driver.get(\"https://en.yna.co.kr/search/index?lang=EN&query=yoon\")\n",
    "\n",
    "    #---------------------------------------------- 스크롤 다운\n",
    "    endkey = 1 # 스크롤 다운 시 12개목록씩 추가  -- 총 12*4=48개\n",
    "    while endkey:\n",
    "        # driver.find_element_by_tag_name('body').send_keys(Keys.END)\n",
    "        #ele_path = driver.find_element(By.CSS_SELECTOR, \"# __next > div > div.mainContainer_container__1GEbx > div > div > main > div:nth-child(2) > div.guide_GuidePanel__3S6xd > div > div > button\")\n",
    "        ele_path = driver.find_element(By.XPATH, '//*[@id=\"tabAreaAll\"]/div/a')\n",
    "        # //*[@id=\"container\"]/section/div[1]/div[2]/a[13]        \n",
    "        ## click button\n",
    "        driver.execute_script(\"arguments[0].click();\", ele_path);\n",
    "        time.sleep(2)\n",
    "        endkey -= 1\n",
    "    #---------------------------------------------- lxml\n",
    "    # soup = BeautifulSoup(htmlstr, 'lxml')\n",
    "    # video_list0 = soup.find('div', {'id': 'contents'})\n",
    "    # print(video_list0)\n",
    "    #---------------------------------------------- html.parser\n",
    "    htmlstr = driver.page_source\n",
    "    soup = BeautifulSoup(htmlstr, features=\"html.parser\")\n",
    "    # \"#__next > div > div.mainContainer_container__1GEbx > div > div > main > div:nth-child(2) > div.guide_GuidePanel__3S6xd > div > ul > li:nth-child(1)\"\n",
    "    div_list = soup.select(\"#tabArticle > div.con > div > ul > li\")\n",
    "    #----------------------------------------------\n",
    "    # content_list =[]\n",
    "    news_list = []\n",
    "    for div in div_list: \n",
    "        # tag   = div.select_one(\"#container > section > div.sub-content > div.smain-list-type01 > ul > li > article > div > span.tag\").text\n",
    "        #container > section > div.sub-content > div.smain-list-type01 > ul > li:nth-child(1) > article > div > span.tag\n",
    "        # href     = div.select_one(\"#container > section > div.sub-content > div.smain-list-type01 > ul > li > article > div > h2 > a\").get('href')\n",
    "        title   = div.select_one(\"#tabArticle > div.con > div > ul > li > article > div > h2\").text\n",
    "        # content = div.select_one(\"#container > section > div.sub-content > div.smain-list-type01 > ul > li> article > div > span.lead\").text\n",
    "        # date = div.select_one(\"#container > section > div.sub-content > div.smain-list-type01 > ul > li > article > div > span.date\").text\n",
    "\n",
    "        # img = div.select_one(\"div > a > figure > img\").get('src')\n",
    "        # print(title, url)\n",
    "        # movie_list.append([url])\n",
    "        news_list.append([title])\n",
    "        \n",
    "#         response_sub = requests.get(href)\n",
    "#         if response_sub.status_code == 200:\n",
    "#             interval = round(random.uniform(0.2, 1.2), 2)\n",
    "#             time.sleep(interval)\n",
    "\n",
    "\n",
    "#             html_sub = response_sub.text\n",
    "#             html_soup = BeautifulSoup(html_sub, 'html.parser')\n",
    "#             content = html_soup.select_one(\"#container > section > article > div.view-body > div.sub-content > article\").text\n",
    "#             temp = \"\"\n",
    "#             for cc in content.rsplit(\"\\n\"):\n",
    "#                 if len(cc) > 2:\n",
    "#                     temp += cc\n",
    "#             print(temp)\n",
    "#             try:\n",
    "#                 content_list.append(temp)\n",
    "#                 # sql = \"insert into craw_ytn_news(seq, title, content, cate, rdate) values (craw_ytn_news_seq.nextval,  :2, :3, :4, :5)\"\n",
    "#                 # conn.execute(sql, (title, temp, cate, rdate))\n",
    "#             except Exception as e:\n",
    "#                 continue\n",
    "#                 # trans.rollback()\n",
    "#                 # print(e)\n",
    "#                 print(\"에러발생\")\n",
    "#         else:\n",
    "#             print(\"에러발생\" + response.status_code)\n",
    "#     trans.commit()\n",
    "\n",
    "#     df_news = pd.DataFrame(news_list, columns=[\"title\",\"href\",\"content\",\"date\"])\n",
    "#     df_news.to_csv(\"./datasets/yonhap1.csv\", index=False)\n",
    "    \n",
    "#     df_cont = pd.DataFrame(content_list, columns=[\"cont\"])\n",
    "#     df_cont.to_csv(\"./datasets/yonhap2.csv\", index=False)    \n",
    "    # return news_list,content_list\n",
    "    print(news_list)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# a,b=mysearch()\n",
    "# print(len(div_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f353f97-385d-4cb8-a121-ad30875da5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://en.yna.co.kr/search/index?&ctype=A&lang=EN&query=\" + search + \"&page_no=\" + str(no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f1be686b-b1cf-44b6-b43e-69d95c78a3fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# mysearch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38893eb-f4c7-4bf8-b54c-2da80f6409d4",
   "metadata": {},
   "source": [
    "# 찐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7f7587ef-a4e5-42ad-a3cb-41da665bdee6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "0a4eb61f-657d-405a-9a28-85f27e6c931c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def crawling(search, no):\n",
    "    htmlstr =requests.get(\"https://en.yna.co.kr/search/index?query=yoon&ctype=A&lang=EN&page_no=1\")\n",
    "    soup = BeautifulSoup(htmlstr.text, features=\"html.parser\")\n",
    "    # \"#__next > div > div.mainContainer_container__1GEbx > div > div > main > div:nth-child(2) > div.guide_GuidePanel__3S6xd > div > ul > li:nth-child(1)\"\n",
    "    div_list = soup.select(\"#tabArticle > div.con > div > ul\")\n",
    "    #----------------------------------------------\n",
    "    # content_list =[]\n",
    "    # news_list = []\n",
    "    # for div in div_list: \n",
    "    #     # tag   = div.select_one(\"#container > section > div.sub-content > div.smain-list-type01 > ul > li > article > div > span.tag\").text\n",
    "    #     #container > section > div.sub-content > div.smain-list-type01 > ul > li:nth-child(1) > article > div > span.tag\n",
    "    #     href     = div.select_one(\"li > article > div > h2 > a\").get('href')\n",
    "        # title   = div.select_one(\"li > article > div > h2 > a\").text\n",
    "        #tabArticle > div.con > div > ul > li:nth-child(1) > article > div > h2 > a\n",
    "    #     content = div.select_one(\"li > article > div > span.lead\").text\n",
    "    #     date = div.select_one(\"li > article > div > span.date.datefm-EN01\").text\n",
    "    #     news_list.apend([title, href,content,date])\n",
    "\n",
    "    \n",
    "#     df_news = pd.DataFrame(news_list, columns=[\"title\",\"href\",\"content\",\"date\"])\n",
    "#     df_news.to_csv(\"./datasets/yonhap_list.csv\", index=False)\n",
    "    print( div_list)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "ff6dd13c-2617-4aa7-95ee-38eec3d0e19d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<ul>\n",
      "</ul>]\n"
     ]
    }
   ],
   "source": [
    "crawling(\"yoon\",1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a693b5d-0f39-4fa0-8fc9-680356271a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def craw(urlprm, cate):\n",
    "    # with oracle_engine.connect() as conn:\n",
    "    #     trans = conn.begin()\n",
    "\n",
    "        for pageno in range(1, 7, 1):\n",
    "            interval = round(random.uniform(0.2, 1.2), 2)\n",
    "            time.sleep(interval)\n",
    "            #------------------------------------------------\n",
    "            url =  urlprm + str(pageno)\n",
    "            print(url)\n",
    "            \n",
    "            response = requests.get(url)\n",
    "            if response.status_code == 200:\n",
    "                html = response.text\n",
    "                soup = BeautifulSoup(html, 'html.parser')\n",
    "                list = soup.select(\"#zone1 > div > div.newslist_wrap > div > ul > li\")\n",
    "\n",
    "                news_list = []\n",
    "                for i, li_tag in enumerate(list):\n",
    "\n",
    "                    dict = {}\n",
    "                    title   = li_tag.select_one('a > div > span').text\n",
    "                    rdate   = li_tag.select_one('a > div > div > span.date').text\n",
    "                    href     = li_tag.select_one('a').get(\"href\")\n",
    "                    #content.00 = li_tag.select_one('a > div > div > span.desc').text\n",
    "\n",
    "                    dict['key_title'] = title\n",
    "                    dict['key_rdate'] = rdate\n",
    "                    dict['key_href'] = href\n",
    "                    # dict['key_content'] = content\n",
    "                    news_list.append(dict)\n",
    "\n",
    "                    print(href)\n",
    "                    response_sub = requests.get(href)\n",
    "                    if response_sub.status_code == 200:\n",
    "                        interval = round(random.uniform(0.2, 1.2), 2)\n",
    "                        time.sleep(interval)\n",
    "\n",
    "\n",
    "                        html_sub = response_sub.text\n",
    "                        html_soup = BeautifulSoup(html_sub, 'html.parser')\n",
    "                        content = html_soup.select_one(\"div#CmAdContent > span\").text\n",
    "                        temp = \"\"\n",
    "                        for cc in content.rsplit(\"\\n\"):\n",
    "                            if len(cc) > 2:\n",
    "                                temp += cc\n",
    "                        print(temp)\n",
    "                        try:\n",
    "                            sql = \"insert into craw_ytn_news(seq, title, content, cate, rdate) values (craw_ytn_news_seq.nextval,  :2, :3, :4, :5)\"\n",
    "                            conn.execute(sql, (title, temp, cate, rdate))\n",
    "                        except Exception as e:\n",
    "                            continue\n",
    "                            # trans.rollback()\n",
    "                            # print(e)\n",
    "                            print(\"에러발생\")\n",
    "            else:\n",
    "                print(\"에러발생\" + response.status_code)\n",
    "        trans.commit()\n",
    "    return news_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "0adf7197-73be-4bb3-b46f-ebb8eaf05b70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def craw(search):\n",
    "    url = \"https://en.yna.co.kr/search/index?&ctype=A&lang=EN&query=\" + search\n",
    "    print(url)\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        html = response.text\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        div_list = soup.select(\"#tabArticle > div.con > div > ul\")\n",
    "    else:\n",
    "                print(\"에러발생\" + response.status_code)\n",
    "    print(div_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "aaff01c7-2974-4ea9-b818-0ec8c36a241c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://en.yna.co.kr/search/index?&ctype=A&lang=EN&query=yoon\n",
      "[<ul>\n",
      "</ul>]\n"
     ]
    }
   ],
   "source": [
    "craw(\"yoon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03aea2ce-e50d-49bc-b890-e587979eb163",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://en.yna.co.kr/search/index?&ctype=A&lang=EN&query=\" + search + \"&page_no=\" + str(no)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
