{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1845c8c-3cde-46d0-82b7-d405056e7bda",
   "metadata": {},
   "source": [
    "# 한국경제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4bbe93c1-90c3-4496-9a78-bbe4b6ca91af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from konlpy.tag import Okt\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c27f4cf8-d2c1-4744-aa7d-7ecae202a529",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sqlalchemy as sa\n",
    "import cx_Oracle\n",
    "import xml.etree.ElementTree as ET\n",
    "import json\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "# random.uniform(0.2, 1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f86fe656-72e3-4eae-a3e9-37c5c89d142c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5773de1-44bc-48e7-8083-555fb02b9663",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas as pd\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "729eb155-af28-42fc-ac00-e40b67b759ca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.42037998, 0.56619778, 0.92492945])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interval = np.random.random_sample(3)\n",
    "interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fcab35b2-495c-4f47-bdba-c630a01d06d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "headers = {\n",
    "\"User-Agent\":\n",
    "\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/113.0.0.0 Safari/537.36\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06a3c94e-fa0e-45c7-b723-d739be66e16b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def craw_search(search):\n",
    "    news_list = []\n",
    "    for pageno in range(1201,1501, 1):\n",
    "        interval = np.random.random_sample()\n",
    "        interval *= 10\n",
    "        time.sleep(interval)\n",
    "        #------------------------------------------------\n",
    "        url = \"https://search.hankyung.com/search/news?query=\" +search + \"&page=\" + str(pageno)\n",
    "        # print(url)\n",
    "\n",
    "        response = requests.get(url,headers=headers)\n",
    "        # print(response)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            html = response.text\n",
    "            soup = BeautifulSoup(html, 'html.parser')\n",
    "            div_list = soup.select(\"#content > div.left_cont > div > div.section.hk_news > div > ul > li\")\n",
    "            # print(div_list)\n",
    "            \n",
    "            for i, li_tag in enumerate(div_list):\n",
    "\n",
    "                dict = {}\n",
    "                title = li_tag.select_one('#content > div.left_cont > div > div.section.hk_news > div > ul > li > div > a > em').text\n",
    "                rdate = li_tag.select_one('#content > div.left_cont > div > div.section.hk_news > div > ul > li > div > p.info > span.date_time').text\n",
    "                # href = li_tag.select_one('#container > div.article_list_left > div > ul > li > p.title > a').get(\"href\")\n",
    "                cont = li_tag.select_one('#content > div.left_cont > div > div.section.hk_news > div > ul > li > div > p').text\n",
    "               \n",
    "\n",
    "                dict['key_title'] = title\n",
    "                dict['key_rdate'] = rdate\n",
    "                # dict['key_href'] = href\n",
    "                dict['key_cont'] = cont\n",
    "\n",
    "# #                 # dict['key_content'] = content\n",
    "                news_list.append(dict)\n",
    "        else:\n",
    "            print(\"에러발생\" + response.status_code)\n",
    "            \n",
    "    df = pd.DataFrame(news_list)#, columns = [\"title\",\"rdate\",\"href\",\"cont\"])\n",
    "    df.to_csv(\"./data/han1500.csv\", index=False)\n",
    "    return news_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "268db386-dfaf-468a-9bb8-ffa826d5ce6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# a = craw_search(\"펀드\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed37390f-8c86-469c-9756-552f17989e51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43280da4-9547-4030-84f2-53be4d154eef",
   "metadata": {},
   "source": [
    "# 셀레늄"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
