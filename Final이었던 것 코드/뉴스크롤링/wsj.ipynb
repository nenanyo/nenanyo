{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "136e0374-83e5-490f-a0ef-4c1f1601440b",
   "metadata": {},
   "source": [
    " # wall street journal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "068db7ed-3189-4d09-a6d8-861c25ce1047",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from konlpy.tag import Okt\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7db25699-8648-4550-8991-3d52922d382e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sqlalchemy as sa\n",
    "import cx_Oracle\n",
    "import xml.etree.ElementTree as ET\n",
    "import json\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "# random.uniform(0.2, 1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f9a9b10-3add-4262-9641-a90c46114dd6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4833f6c3-8c5c-42f2-a2ae-53d56cbfdc9d",
   "metadata": {},
   "source": [
    "# bs4단독 XXXX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d2173530-2e09-462e-85a0-c19d09bf3b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def craw(search):\n",
    "    # with oracle_engine.connect() as conn:\n",
    "    #     trans = conn.begin()\n",
    "\n",
    "        for pageno in range(1, 1, 1):\n",
    "            interval = round(random.uniform(0.2, 1.2), 2)\n",
    "            time.sleep(interval)\n",
    "            #------------------------------------------------\n",
    "            url =  \"https://www.wsj.com/search?query=\" + search + \"&mod=searchresults_viewallresults&page=\" + str(pageno)\n",
    "            print(url)\n",
    "            \n",
    "            response = requests.get(url)\n",
    "            response\n",
    "            # if response.status_code == 200:\n",
    "            #     print (200)\n",
    "            # else:\n",
    "            #     print (\"error\")\n",
    "#                 html = response.text\n",
    "#                 soup = BeautifulSoup(html, 'html.parser')\n",
    "#                 list = soup.select(\"#main > div > article > div\")\n",
    "\n",
    "#                 news_list = []\n",
    "#                 for i, li_tag in enumerate(list):\n",
    "\n",
    "#                     dict = {}\n",
    "#                     title   = li_tag.select_one('#main > div > article > div > div.WSJTheme--search-text-combined--29JN8aap > div.WSJTheme--search-combined-headline-summary--1bmOvoTg > div.WSJTheme--headline--7VCzo7Ay > h3 > a > span').text\n",
    "#                     rdate   = li_tag.select_one('#main > div > article > div > div.WSJTheme--search-text-combined--29JN8aap > div.WSJTheme--search-combined-byline-timestamp--kmgehrO6 > div > p').text\n",
    "#                     href     = li_tag.select_one('#main > div > article > div > div.WSJTheme--search-text-combined--29JN8aap > div.WSJTheme--search-combined-headline-summary--1bmOvoTg > div.WSJTheme--headline--7VCzo7Ay > h3 > a').get(\"href\")\n",
    "# #                     #content.00 = li_tag.select_one('a > div > div > span.desc').text\n",
    "\n",
    "#                     dict['key_title'] = title\n",
    "#                     dict['key_rdate'] = rdate\n",
    "#                     dict['key_href'] = href\n",
    "# #                     # dict['key_content'] = content\n",
    "#                     news_list.append(dict)\n",
    "#                     return news_list\n",
    "\n",
    "#                     print(href)\n",
    "#                     response_sub = requests.get(href)\n",
    "#                     if response_sub.status_code == 200:\n",
    "#                         interval = round(random.uniform(0.2, 1.2), 2)\n",
    "#                         time.sleep(interval)\n",
    "\n",
    "\n",
    "#                         html_sub = response_sub.text\n",
    "#                         html_soup = BeautifulSoup(html_sub, 'html.parser')\n",
    "#                         content = html_soup.select_one(\"div#CmAdContent > span\").text\n",
    "#                         temp = \"\"\n",
    "#                         for cc in content.rsplit(\"\\n\"):\n",
    "#                             if len(cc) > 2:\n",
    "#                                 temp += cc\n",
    "#                         print(temp)\n",
    "#                         # try:\n",
    "#                         #     sql = \"insert into craw_ytn_news(seq, title, content, cate, rdate) values (craw_ytn_news_seq.nextval,  :2, :3, :4, :5)\"\n",
    "#                         #     conn.execute(sql, (title, temp, cate, rdate))\n",
    "#                         # except Exception as e:\n",
    "#                         #     continue\n",
    "#                         #     # trans.rollback()\n",
    "#                         #     # print(e)\n",
    "#                         #     print(\"에러발생\")\n",
    "            # else:\n",
    "            #     print(\"에러발생\" + response.status_code)\n",
    "#         trans.commit()\n",
    "    # return news_list\n",
    "\n",
    "# # -------------------------- 각 6종 분야별 뉴스 1010 건 ---------------------------------------\n",
    "# # 경제_list = craw(\"https://www.ytn.co.kr/news/list.php?mcd=0101&page=\",1)       #263 rows\n",
    "# # 사회_list = craw(\"https://www.ytn.co.kr/news/list.php?mcd=0102&page=\",2)       #262 rows\n",
    "# # 과학_list = craw(\"https://www.ytn.co.kr/news/list.php?mcd=0105&page=\",3)       #180 rows\n",
    "# # 문화_list = craw(\"https://www.ytn.co.kr/news/list.php?mcd=0106&page=\",4)       #266 rows\n",
    "# # 재난_list = craw(\"https://www.ytn.co.kr/news/list.php?mcd=S0018&page=\",5)      #266 rows\n",
    "# # 날씨_list = craw(\"https://www.ytn.co.kr/weather/list_weather.php?page=\",6)     #297 rows\n",
    "\n",
    "\n",
    "\n",
    "# # -------------------------- DB에서 읽어와 DataFrame 생성 ---------------------------------------\n",
    "# # from sqlalchemy import types, create_engine\n",
    "# # oracle_engine = create_engine('oracle://conf:0000@localhost:1521/XE')\n",
    "# sql = \"select title, content, cate, rdate from craw_ytn_news\"\n",
    "# df = pd.read_sql_query(f'''{sql}''', oracle_engine)\n",
    "# print(df.head())\n",
    "# df.to_csv(\"./datasets/craw_ytn_news.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4ec6b3c1-78fb-481a-96a7-8689c2dc7a7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "craw(\"fed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771654f7-9dbc-45e4-af66-5c456d56cecd",
   "metadata": {},
   "source": [
    "# 셀레늄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6af31bd2-09b3-4d5f-8b6d-14a308f2f2ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mysearch(search) :\n",
    "    for pageno in range(1, 2, 1):\n",
    "            interval = round(random.uniform(0.2, 1.2), 2)\n",
    "            time.sleep(interval)\n",
    "            #------------------------------------------------\n",
    "            url =  \"https://www.wsj.com/search?query=\" + search + \"&mod=searchresults_viewallresults&page=\" + str(pageno)\n",
    "            # print(url)\n",
    "    \n",
    "            driver = webdriver.Chrome('chromedriver_110.exe')\n",
    "            driver.get(url)\n",
    "            htmlstr = driver.page_source\n",
    "\n",
    "            # return htmlstr\n",
    "        #----------------------------------------------\n",
    "            soup = BeautifulSoup(htmlstr, features=\"html.parser\")\n",
    "            div_list = soup.select(\"#main > div > article > div\")\n",
    "            news_list = []\n",
    "            for div in div_list: \n",
    "                href     = div.select_one(\"#main > div > article > div > div.WSJTheme--search-text-combined--29JN8aap > div.WSJTheme--search-combined-headline-summary--1bmOvoTg > div.WSJTheme--headline--7VCzo7Ay > h3 > a\").get('href')\n",
    "                title   = div.select_one(\"#main > div > article > div > div.WSJTheme--search-text-combined--29JN8aap > div.WSJTheme--search-combined-headline-summary--1bmOvoTg > div.WSJTheme--headline--7VCzo7Ay > h3 > a > span\").text\n",
    "                content = div.select_one(\"#main > div > article > div > div.WSJTheme--search-text-combined--29JN8aap > div.WSJTheme--search-combined-headline-summary--1bmOvoTg > p > span\").text\n",
    "    #             # img = div.select_one(\"div > a > figure > img\").get('src')\n",
    "    #             # print(title, url)\n",
    "    #             # movie_list.append([url])\n",
    "                news_list.append([title, href,content])\n",
    "            return news_list\n",
    "\n",
    "#     df_news = pd.DataFrame(movie_list, columns=[\"title\",\"href\",\"content\"])\n",
    "#     df_news.to_csv(\"./datasets/joong2.csv\", index=False)\n",
    "#     # df_cont.to_csv(\"./datasets/joong3.csv\", index=False)\n",
    "#     return movie_list\n",
    "\n",
    "\n",
    "# a=mysearch()\n",
    "# print(len(div_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0a24b7b5-a708-40e1-8886-66ac8faecf3b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASIA\\AppData\\Local\\Temp\\ipykernel_30784\\3018562053.py:9: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome('chromedriver_110.exe')\n"
     ]
    }
   ],
   "source": [
    "a=mysearch(\"fed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "00cc89c0-dca5-4a10-b49c-b8b1998dfa07",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
