{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e837636e-c2a8-4825-8524-b3c70896cf3b",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3afd04a7-0e8c-450b-9f52-8a2a77a00dc7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0298465896631537"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sqlalchemy as sa\n",
    "import cx_Oracle\n",
    "import xml.etree.ElementTree as ET\n",
    "import json\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "random.uniform(0.2, 1.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "346e19e0-6cf8-448e-81ac-7a7862a9b325",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5ed332-4228-472d-86bb-14daf1592641",
   "metadata": {},
   "source": [
    "# 검색 리스트 크롤링"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdf6ed5-f3ee-4e50-b01c-a42e63afed04",
   "metadata": {},
   "source": [
    "## bs4 단독    XXXXX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "306c25fb-8492-4821-bc69-5179c1d2d80d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def craw_search(search):\n",
    "    news_list = []\n",
    "    \n",
    "    for pageno in range(1, 3, 1):\n",
    "        interval = round(random.uniform(0.2, 1.2), 2)\n",
    "        time.sleep(interval)\n",
    "        #------------------------------------------------\n",
    "        url = \"https://edition.cnn.com/search?q=\" + search + \"&from=\"+str((pageno-1)*50) + \"&size=50&page=\" +str(pageno)  + \"&sort=newest&types=all&section=business\"\n",
    "        # print(url)\n",
    "        \n",
    "        response = requests.get(url)\n",
    "        # print(response)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            html = response.text\n",
    "            soup = BeautifulSoup(html, 'html.parser')\n",
    "            div_list = soup.select(\"#search > div.search__right > div > div.search__results-list > div > a > div\")\n",
    "            print(div_list)\n",
    "            \n",
    "#             for i, li_tag in enumerate(div_list):\n",
    "\n",
    "#                 dict = {}\n",
    "#                 title = li_tag.select_one('#container > div.article_list_left > div > ul > li > p.title > a').text\n",
    "#                 rdate = li_tag.select_one('#container > div.article_list_left > div > ul > li > span').text\n",
    "#                 href = li_tag.select_one('#container > div.article_list_left > div > ul > li > p.title > a').get(\"href\")\n",
    "#                 cont = li_tag.select_one('#container > div.article_list_left > div > ul > li > p.txt > a').text\n",
    "               \n",
    "\n",
    "#                 dict['key_title'] = title\n",
    "#                 dict['key_rdate'] = rdate\n",
    "#                 dict['key_href'] = href\n",
    "#                 dict['key_cont'] = cont\n",
    "\n",
    "# #                 # dict['key_content'] = content\n",
    "#                 news_list.append(dict)\n",
    "        else:\n",
    "            print(\"에러발생\" + response.status_code)\n",
    "            \n",
    "#     df = pd.DataFrame(news_list)#, columns = [\"title\",\"rdate\",\"href\",\"cont\"])\n",
    "#     df.to_csv(\"./datasets/kh_list_fed.csv\", index=False)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8c1eb797-6ca7-46aa-a72a-b17ed1a5ea07",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "craw_search(\"fed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea01cee2-c4b5-41c1-81b8-29060efc360e",
   "metadata": {},
   "source": [
    "## 셀레늄 + bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1620b16a-bdaf-47f8-8370-8bbcc6244c16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def craw_search(search):\n",
    "    news_list = []\n",
    "    \n",
    "    for pageno in range(1, 3, 1):\n",
    "        interval = round(random.uniform(0.2, 1.2), 2)\n",
    "        time.sleep(interval)\n",
    "        #------------------------------------------------\n",
    "        url = \"https://edition.cnn.com/search?q=\" + search + \"&from=\"+str((pageno-1)*50) + \"&size=50&page=\" +str(pageno)  + \"&sort=newest&types=all&section=business\"\n",
    "        # print(url)\n",
    "        driver = webdriver.Chrome('chromedriver_110.exe')\n",
    "        driver.get(url)\n",
    "\n",
    "        #---------------------------------------------- 스크롤 다운\n",
    "        # endkey = 1 # 스크롤 다운 시 12개목록씩 추가  -- 총 12*4=48개\n",
    "        # while endkey:\n",
    "        #     # driver.find_element_by_tag_name('body').send_keys(Keys.END)\n",
    "        #     #ele_path = driver.find_element(By.CSS_SELECTOR, \"# __next > div > div.mainContainer_container__1GEbx > div > div > main > div:nth-child(2) > div.guide_GuidePanel__3S6xd > div > div > button\")\n",
    "        #     ele_path = driver.find_element(By.XPATH, '//*[@id=\"tabAreaAll\"]/div/a')\n",
    "        #     # //*[@id=\"container\"]/section/div[1]/div[2]/a[13]        \n",
    "        #     ## click button\n",
    "        #     driver.execute_script(\"arguments[0].click();\", ele_path);\n",
    "        #     time.sleep(2)\n",
    "        #     endkey -= 1\n",
    "        #---------------------------------------------- lxml\n",
    "        # soup = BeautifulSoup(htmlstr, 'lxml')\n",
    "        # video_list0 = soup.find('div', {'id': 'contents'})\n",
    "        # print(video_list0)\n",
    "        #---------------------------------------------- html.parser\n",
    "        htmlstr = driver.page_source\n",
    "        soup = BeautifulSoup(htmlstr, features=\"html.parser\")\n",
    "        # \"#__next > div > div.mainContainer_container__1GEbx > div > div > main > div:nth-child(2) > div.guide_GuidePanel__3S6xd > div > ul > li:nth-child(1)\"\n",
    "        div_list = soup.select(\"#search > div.search__right > div> div.search__results-list\")#> div > a > div\")\n",
    "        # print(div_list)\n",
    "\n",
    "        # if response.status_code == 200:\n",
    "        #     html = response.text\n",
    "        #     soup = BeautifulSoup(html, 'html.parser')\n",
    "        #     div_list = soup.select(\"#search > div.search__right > div > div.search__results-list > div > a > div\")\n",
    "        #     print(div_list)\n",
    "            \n",
    "        for i, li_tag in enumerate(div_list):\n",
    "\n",
    "            dict = {}\n",
    "            # title = li_tag.select_one('#search > div.search__right > div > div.search__results-list > div > a > div').text\n",
    "            # rdate = li_tag.select_one('#search > div.search__right > div > div.search__results-list > div > a > div > div.container__date.__date.inline-placeholder').text\n",
    "            href = li_tag.select_one('#search > div > div > div > div > a > div').get(\"data-zjs-href\")\n",
    "            # cont = li_tag.select_one('#container > div.article_list_left > div > ul > li > p.txt > a').text\n",
    "\n",
    "\n",
    "            # dict['key_title'] = title\n",
    "            # dict['key_rdate'] = rdate\n",
    "            dict['key_href'] = href\n",
    "            # dict['key_cont'] = cont\n",
    "\n",
    "#                 # dict['key_content'] = content\n",
    "            news_list.append(dict)\n",
    "        # else:\n",
    "        #     print(\"에러발생\" + response.status_code)\n",
    "            \n",
    "    df = pd.DataFrame(news_list)#, columns = [\"title\",\"rdate\",\"href\",\"cont\"])\n",
    "    df.to_csv(\"./datasets/cnn_list_fed.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "15611bfb-856e-42a7-ab8f-42b3623eaa10",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASIA\\AppData\\Local\\Temp\\ipykernel_14184\\1410157063.py:10: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome('chromedriver_110.exe')\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'get'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[71], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mcraw_search\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[70], line 46\u001b[0m, in \u001b[0;36mcraw_search\u001b[1;34m(search)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28mdict\u001b[39m \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# title = li_tag.select_one('#search > div.search__right > div > div.search__results-list > div > a > div').text\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# rdate = li_tag.select_one('#search > div.search__right > div > div.search__results-list > div > a > div > div.container__date.__date.inline-placeholder').text\u001b[39;00m\n\u001b[1;32m---> 46\u001b[0m href \u001b[38;5;241m=\u001b[39m \u001b[43mli_tag\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect_one\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m#search > div > div > div > div > a > div\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata-zjs-href\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# cont = li_tag.select_one('#container > div.article_list_left > div > ul > li > p.txt > a').text\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \n\u001b[0;32m     49\u001b[0m \n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# dict['key_title'] = title\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;66;03m# dict['key_rdate'] = rdate\u001b[39;00m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkey_href\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m href\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'get'"
     ]
    }
   ],
   "source": [
    "craw_search(\"fed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4ecb30-305f-4aaf-b070-52a3fd988125",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525326c7-ba9d-43a8-ab1d-20a4ca3de2cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
